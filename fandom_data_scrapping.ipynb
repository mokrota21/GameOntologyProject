{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_fandom(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    infobox = soup.find(class_=lambda class_name: class_name and 'infobox' in class_name)\n",
    "    return infobox\n",
    "\n",
    "def extract_grouped_text(element):\n",
    "    if isinstance(element, NavigableString):\n",
    "        return element.strip()\n",
    "\n",
    "    if not element.contents:\n",
    "        return []\n",
    "\n",
    "    grouped_text = []\n",
    "    current_text = []\n",
    "\n",
    "    for child in element.contents:\n",
    "        if isinstance(child, NavigableString):\n",
    "            text = child.strip()\n",
    "            if text:\n",
    "                current_text.append(text)\n",
    "        elif isinstance(child, Tag):\n",
    "            if child.name == 'br':\n",
    "                pass\n",
    "                # current_text.append(' ')  # Add space instead of creating a new entry\n",
    "            else:\n",
    "                if current_text:\n",
    "                    grouped_text.append(' '.join(current_text))\n",
    "                    current_text = []\n",
    "                child_group = extract_grouped_text(child)\n",
    "                if child_group:\n",
    "                    grouped_text.append(child_group)\n",
    "\n",
    "    if current_text:\n",
    "        grouped_text.append(' '.join(current_text))\n",
    "\n",
    "    if len(grouped_text) == 1:\n",
    "        return grouped_text[0]\n",
    "    return grouped_text\n",
    "\n",
    "def strip_list(l):\n",
    "    for i in range(len(l)):\n",
    "        while len(l[i]) == 1 and isinstance(l[i], list):\n",
    "            l[i] = l[i][0]\n",
    "        if isinstance(l[i], list):\n",
    "            l[i] = strip_list(l[i])\n",
    "    return l\n",
    "\n",
    "# Assume that first element is alway key (string)\n",
    "# List may be of length 2 or more\n",
    "# If length 2 than second item is value\n",
    "# Otherwise we combine everything after 1st element as a list \n",
    "# In both cases recursively apply grouped_to_dict to all elements\n",
    "def grouped_to_dict(clear_groups):\n",
    "    # print(clear_groups)\n",
    "    res = {}\n",
    "    key = clear_groups[0]\n",
    "    while not isinstance(key, str):\n",
    "        key = key[0]\n",
    "    if len(clear_groups) == 2 and isinstance(clear_groups[1], str):\n",
    "        res[key] = clear_groups[1]\n",
    "    elif len(clear_groups) == 2:\n",
    "        res[key] = grouped_to_dict(clear_groups[1])\n",
    "    elif len(clear_groups) > 2 and isinstance(clear_groups[1], str):\n",
    "        res[key] = grouped_to_dict(clear_groups[1:])\n",
    "    else:\n",
    "        value = []\n",
    "        for i in range(1, len(clear_groups)):\n",
    "            value.append(grouped_to_dict(clear_groups[i]))\n",
    "        # print(key)\n",
    "        res[key] = value\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "with open('my_list.json', 'w') as f:\n",
    "    json.dump(my_list, f)\n",
    "\n",
    "with open('my_list.json', 'r') as f:\n",
    "    loaded_list = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_infobox(page_url):\n",
    "    data_dict = None\n",
    "    infobox = extract_info_fandom(page_url)\n",
    "    if infobox:\n",
    "        grouped_text = extract_grouped_text(infobox)\n",
    "        if grouped_text:\n",
    "            clear_groups = strip_list(grouped_text)\n",
    "            if clear_groups:\n",
    "                data_dict = grouped_to_dict(clear_groups)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_fandom(game_head):\n",
    "    head_url = game_head\n",
    "    all_pages_tail = 'wiki/Special:AllPages'\n",
    "    all_pages_url = head_url + all_pages_tail\n",
    "    response = requests.get(all_pages_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    all_pages = soup.find('ul', {'class': 'mw-allpages-chunk'})\n",
    "    pages = all_pages.find_all('li')\n",
    "    pages_urls = []\n",
    "    for page in pages:\n",
    "        tail = page.find('a').get('href')\n",
    "        url = head_url + tail\n",
    "        pages_urls.append(url)\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    for page_url in pages_urls:\n",
    "        d = extract_infobox(page_url)\n",
    "        if d:\n",
    "            data.append(d)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('fandom_en_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fandom_url'] = df['fandom_url'].apply(lambda url: url[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def dataset_name(game_name):\n",
    "    return re.sub('[^0-9a-zA-Z]+', '', game_name)[:63].lower() + '.json'\n",
    "\n",
    "df['file_path'] = df['Title'].apply(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fandom_url</th>\n",
       "      <th>Title</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://GrandTheftAutoV.fandom.com/</td>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>grandtheftautov.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://BaldursGate3.fandom.com/</td>\n",
       "      <td>Baldur's Gate 3</td>\n",
       "      <td>baldursgate3.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://EldenRing.fandom.com/</td>\n",
       "      <td>Elden Ring</td>\n",
       "      <td>eldenring.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://TheLastofUs.fandom.com/</td>\n",
       "      <td>The Last of Us</td>\n",
       "      <td>thelastofus.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://RedDeadRedemption.fandom.com/</td>\n",
       "      <td>Red Dead Redemption</td>\n",
       "      <td>reddeadredemption.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>https://XRebirth.fandom.com/</td>\n",
       "      <td>X Rebirth</td>\n",
       "      <td>xrebirth.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>https://Magus.fandom.com/</td>\n",
       "      <td>Magus</td>\n",
       "      <td>magus.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>https://Ghostbusters.fandom.com/</td>\n",
       "      <td>Ghostbusters</td>\n",
       "      <td>ghostbusters.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>https://WildWestOnline.fandom.com/</td>\n",
       "      <td>Wild West Online</td>\n",
       "      <td>wildwestonline.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>https://TheQuietMan.fandom.com/</td>\n",
       "      <td>The Quiet Man</td>\n",
       "      <td>thequietman.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1590 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 fandom_url                Title  \\\n",
       "0       https://GrandTheftAutoV.fandom.com/   Grand Theft Auto V   \n",
       "1          https://BaldursGate3.fandom.com/      Baldur's Gate 3   \n",
       "2             https://EldenRing.fandom.com/           Elden Ring   \n",
       "3           https://TheLastofUs.fandom.com/       The Last of Us   \n",
       "4     https://RedDeadRedemption.fandom.com/  Red Dead Redemption   \n",
       "...                                     ...                  ...   \n",
       "1585           https://XRebirth.fandom.com/            X Rebirth   \n",
       "1586              https://Magus.fandom.com/                Magus   \n",
       "1587       https://Ghostbusters.fandom.com/         Ghostbusters   \n",
       "1588     https://WildWestOnline.fandom.com/     Wild West Online   \n",
       "1589        https://TheQuietMan.fandom.com/        The Quiet Man   \n",
       "\n",
       "                   file_path  \n",
       "0       grandtheftautov.json  \n",
       "1          baldursgate3.json  \n",
       "2             eldenring.json  \n",
       "3           thelastofus.json  \n",
       "4     reddeadredemption.json  \n",
       "...                      ...  \n",
       "1585           xrebirth.json  \n",
       "1586              magus.json  \n",
       "1587       ghostbusters.json  \n",
       "1588     wildwestonline.json  \n",
       "1589        thequietman.json  \n",
       "\n",
       "[1590 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_headers, game_paths = df['fandom_url'].to_list(), df['file_path'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for https://GrandTheftAutoV.fandom.com/ in path grandtheftautov.json\n",
      "Saved data for https://BaldursGate3.fandom.com/ in path baldursgate3.json\n",
      "Saved data for https://EldenRing.fandom.com/ in path eldenring.json\n",
      "Saved data for https://TheLastofUs.fandom.com/ in path thelastofus.json\n",
      "Saved data for https://RedDeadRedemption.fandom.com/ in path reddeadredemption.json\n",
      "Saved data for https://GodofWar.fandom.com/ in path godofwar.json\n",
      "Saved data for https://AstroBot.fandom.com/ in path astrobot.json\n",
      "Saved data for https://TheLegendofZeldaSkywardSword.fandom.com/ in path thelegendofzeldaskywardsword.json\n",
      "Saved data for https://Hades.fandom.com/ in path hades.json\n",
      "Saved data for https://Uncharted4AThiefsEnd.fandom.com/ in path uncharted4athiefsend.json\n",
      "Saved data for https://SuperSmashBrosUltimate.fandom.com/ in path supersmashbrosultimate.json\n",
      "Saved data for https://INSIDE.fandom.com/ in path inside.json\n",
      "Saved data for https://Uncharted3DrakesDeception.fandom.com/ in path uncharted3drakesdeception.json\n",
      "Saved data for https://Bloodborne.fandom.com/ in path bloodborne.json\n",
      "Saved data for https://DemonsSouls.fandom.com/ in path demonssouls.json\n",
      "Saved data for https://UFO50.fandom.com/ in path ufo50.json\n",
      "Saved data for https://Undertale.fandom.com/ in path undertale.json\n",
      "Saved data for https://Journey.fandom.com/ in path journey.json\n",
      "Failed to collect data for https://MarioKart8Deluxe.fandom.com/ in path mariokart8deluxe.json\n",
      "Saved data for https://IWasaTeenageExocolonist.fandom.com/ in path iwasateenageexocolonist.json\n",
      "Saved data for https://Overwatch.fandom.com/ in path overwatch.json\n",
      "Saved data for https://MLB10TheShow.fandom.com/ in path mlb10theshow.json\n",
      "Saved data for https://ForzaMotorsport4.fandom.com/ in path forzamotorsport4.json\n",
      "Saved data for https://AnimalWell.fandom.com/ in path animalwell.json\n",
      "Saved data for https://DiscoElysium.fandom.com/ in path discoelysium.json\n",
      "Saved data for https://ResidentEvil2.fandom.com/ in path residentevil2.json\n",
      "Saved data for https://AnimalCrossingNewHorizons.fandom.com/ in path animalcrossingnewhorizons.json\n",
      "Saved data for https://Bayonetta.fandom.com/ in path bayonetta.json\n",
      "Saved data for https://Balatro.fandom.com/ in path balatro.json\n",
      "Saved data for https://Factorio.fandom.com/ in path factorio.json\n",
      "Saved data for https://JackJeanne.fandom.com/ in path jackjeanne.json\n",
      "Saved data for https://Satisfactory.fandom.com/ in path satisfactory.json\n",
      "Saved data for https://HollowKnight.fandom.com/ in path hollowknight.json\n",
      "Saved data for https://OriandtheWilloftheWisps.fandom.com/ in path oriandthewillofthewisps.json\n",
      "Saved data for https://LIMBO.fandom.com/ in path limbo.json\n",
      "Saved data for https://MarkoftheNinja.fandom.com/ in path markoftheninja.json\n",
      "Saved data for https://ChainedEchoes.fandom.com/ in path chainedechoes.json\n",
      "Saved data for https://SuperMeatBoy.fandom.com/ in path supermeatboy.json\n",
      "Saved data for https://DAVETHEDIVER.fandom.com/ in path davethediver.json\n",
      "Saved data for https://Dota2.fandom.com/ in path dota2.json\n",
      "Saved data for https://GuildWars2.fandom.com/ in path guildwars2.json\n",
      "Saved data for https://Pushmo.fandom.com/ in path pushmo.json\n",
      "Saved data for https://IntotheBreach.fandom.com/ in path intothebreach.json\n",
      "Saved data for https://ChicoryAColorfulTale.fandom.com/ in path chicoryacolorfultale.json\n",
      "Saved data for https://NeonWhite.fandom.com/ in path neonwhite.json\n",
      "Saved data for https://NuclearThrone.fandom.com/ in path nuclearthrone.json\n",
      "Saved data for https://XCOMEnemyUnknown.fandom.com/ in path xcomenemyunknown.json\n",
      "Saved data for https://ApexLegends.fandom.com/ in path apexlegends.json\n",
      "Saved data for https://NORCO.fandom.com/ in path norco.json\n",
      "Saved data for https://Dreams.fandom.com/ in path dreams.json\n",
      "Saved data for https://ReturnoftheObraDinn.fandom.com/ in path returnoftheobradinn.json\n",
      "Saved data for https://LANoire.fandom.com/ in path lanoire.json\n",
      "Saved data for https://DeadCells.fandom.com/ in path deadcells.json\n",
      "Saved data for https://PillarsofEternity.fandom.com/ in path pillarsofeternity.json\n",
      "Saved data for https://PizzaTower.fandom.com/ in path pizzatower.json\n",
      "Saved data for https://AssassinsCreedBrotherhood.fandom.com/ in path assassinscreedbrotherhood.json\n",
      "Saved data for https://SlaytheSpire.fandom.com/ in path slaythespire.json\n",
      "Saved data for https://Titanfall2.fandom.com/ in path titanfall2.json\n",
      "Saved data for https://DarkSouls.fandom.com/ in path darksouls.json\n",
      "Saved data for https://Fez.fandom.com/ in path fez.json\n",
      "Saved data for https://DeadSpace.fandom.com/ in path deadspace.json\n",
      "Saved data for https://CaveStory.fandom.com/ in path cavestory.json\n",
      "Saved data for https://NuclearThrone.fandom.com/ in path nuclearthrone.json\n",
      "Saved data for https://XCOMEnemyUnknown.fandom.com/ in path xcomenemyunknown.json\n",
      "Saved data for https://ApexLegends.fandom.com/ in path apexlegends.json\n",
      "Saved data for https://NORCO.fandom.com/ in path norco.json\n",
      "Saved data for https://Dreams.fandom.com/ in path dreams.json\n",
      "Saved data for https://ReturnoftheObraDinn.fandom.com/ in path returnoftheobradinn.json\n",
      "Saved data for https://LANoire.fandom.com/ in path lanoire.json\n",
      "Saved data for https://Colors3D.fandom.com/ in path colors3d.json\n",
      "Saved data for https://HorizonZeroDawn.fandom.com/ in path horizonzerodawn.json\n",
      "Saved data for https://StardewValley.fandom.com/ in path stardewvalley.json\n",
      "Saved data for https://AsgardsWrath.fandom.com/ in path asgardswrath.json\n",
      "Saved data for https://AShortHike.fandom.com/ in path ashorthike.json\n",
      "Saved data for https://XCOM2WaroftheChosen.fandom.com/ in path xcom2warofthechosen.json\n",
      "Saved data for https://DUSK.fandom.com/ in path dusk.json\n",
      "Saved data for https://Dishonored.fandom.com/ in path dishonored.json\n",
      "Saved data for https://Cocoon.fandom.com/ in path cocoon.json\n",
      "Saved data for https://MarioKart8.fandom.com/ in path mariokart8.json\n",
      "Saved data for https://SuperMarioMaker.fandom.com/ in path supermariomaker.json\n",
      "Saved data for https://KerbalSpaceProgram.fandom.com/ in path kerbalspaceprogram.json\n",
      "Saved data for https://NieRAutomata.fandom.com/ in path nierautomata.json\n",
      "Saved data for https://XCOM2.fandom.com/ in path xcom2.json\n",
      "Saved data for https://HorizonForbiddenWest.fandom.com/ in path horizonforbiddenwest.json\n",
      "Saved data for https://XCOMEnemyWithin.fandom.com/ in path xcomenemywithin.json\n",
      "Saved data for https://ItTakesTwo.fandom.com/ in path ittakestwo.json\n",
      "Saved data for https://Deathloop.fandom.com/ in path deathloop.json\n",
      "Saved data for https://OriandtheBlindForest.fandom.com/ in path oriandtheblindforest.json\n",
      "Saved data for https://SuperMarioMaker2.fandom.com/ in path supermariomaker2.json\n",
      "Saved data for https://TheStanleyParable.fandom.com/ in path thestanleyparable.json\n",
      "Saved data for https://MonsterHunterRise.fandom.com/ in path monsterhunterrise.json\n",
      "Saved data for https://Battlefield1.fandom.com/ in path battlefield1.json\n",
      "Saved data for https://TacticalBreachWizards.fandom.com/ in path tacticalbreachwizards.json\n",
      "Saved data for https://Owlboy.fandom.com/ in path owlboy.json\n",
      "Saved data for https://NightintheWoods.fandom.com/ in path nightinthewoods.json\n",
      "Saved data for https://Nioh.fandom.com/ in path nioh.json\n",
      "Saved data for https://AnimalCrossingNewLeaf.fandom.com/ in path animalcrossingnewleaf.json\n",
      "Saved data for https://Subnautica.fandom.com/ in path subnautica.json\n",
      "Saved data for https://Injustice2.fandom.com/ in path injustice2.json\n",
      "Saved data for https://TheWitness.fandom.com/ in path thewitness.json\n",
      "Failed to collect data for https://RimWorld.fandom.com/ in path rimworld.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for game_header, file_path in zip(game_headers, game_paths):\n",
    "    try:\n",
    "        data = []\n",
    "        data = extract_data_fandom(game_head=game_header)\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(data, json_file)\n",
    "        print(f\"Saved data for {game_header} in path {file_path}\")\n",
    "    except:\n",
    "        with open('failed_scraps.txt', 'a') as logs:\n",
    "            logs.write(game_header)\n",
    "        print(f\"Failed to collect data for {game_header} in path {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
